{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Install Dependencies and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import cv2\n",
    "import imghdr\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import random as python_random\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below is necessary for starting Numpy generated random numbers\n",
    "# in a well-defined initial state.\n",
    "np.random.seed(123)\n",
    "\n",
    "# The below is necessary for starting core Python generated random numbers\n",
    "# in a well-defined state.\n",
    "python_random.seed(123)\n",
    "\n",
    "# The below set_seed() will make random number generation\n",
    "# in the TensorFlow backend have a well-defined initial state.\n",
    "# For further details, see:\n",
    "# https://www.tensorflow.org/api_docs/python/tf/random/set_seed\n",
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Remove dodgy images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "categories = ['Blotch','Normal', 'Rot', 'Scab']\n",
    "\n",
    "train_dir = 'data/Train/'\n",
    "test_dir = 'data/Test/'\n",
    "\n",
    "train_blotch_dir = 'data/Train/Blotch_Apple/'\n",
    "\n",
    "# print (os.listdir(train_dir))\n",
    "\n",
    "print (type(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/Train/Blotch_Apple/\n",
      "data/Train/Normal_Apple/\n",
      "data/Train/Rot_Apple/\n",
      "data/Train/Scab_Apple/\n"
     ]
    }
   ],
   "source": [
    "for i in categories:\n",
    "    print(f\"{train_dir}{i}_Apple/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_exts = ['jpeg','jpg', 'bmp', 'png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_class in os.listdir(train_dir): \n",
    "    for image in os.listdir(os.path.join(train_dir, image_class)): #go to location, here: data/Train / Blotch_Apple\n",
    "        image_path = os.path.join(train_dir, image_class, image) #go to location, here: data/Train / Blotch_Apple / blotch_1.jpg\n",
    "        try: \n",
    "            img = cv2.imread(image_path)\n",
    "           \n",
    "        except Exception as e: \n",
    "            print('Issue with image {}'.format(image_path))\n",
    "            # os.remove(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Load Data\n",
    "\n",
    "Total_train_data aangemaakt om balans tussen klassen in de set weer te geven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 382 files belonging to 4 classes.\n",
      "Found 382 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# data = tf.keras.utils.image_dataset_from_directory('data') changed from relative path to variable\n",
    "total_train_data = tf.keras.utils.image_dataset_from_directory(train_dir, batch_size=382)\n",
    "train_data = tf.keras.utils.image_dataset_from_directory(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>\n"
     ]
    }
   ],
   "source": [
    "print (type(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 116, 1: 67, 2: 114, 3: 85}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    for i in total_train_data.as_numpy_iterator(): \n",
    "        X, y = i\n",
    "    # print (y)  \n",
    "\n",
    "unique2, counts2 = np.unique(y, return_counts=True)\n",
    "dict(zip(unique2, counts2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "blotch 32%, normal 18%, rot 27%, scab 23% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Blotch_Apple', 'Normal_Apple', 'Rot_Apple', 'Scab_Apple']\n"
     ]
    }
   ],
   "source": [
    "# print (train_data.info)\n",
    "print (train_data.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 120 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data = tf.keras.utils.image_dataset_from_directory(test_dir, batch_size=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 30, 1: 24, 2: 38, 3: 28}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    for i in test_data.as_numpy_iterator(): \n",
    "        X, y = i\n",
    "    # print (y)  \n",
    "\n",
    "unique2, counts2 = np.unique(y, return_counts=True)\n",
    "dict(zip(unique2, counts2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_iterator = data.as_numpy_iterator()\n",
    "train_iterator = train_data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iterator = test_data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# batch = data_iterator.next()\n",
    "train_batch = train_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = test_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "  tf.keras.layers.RandomFlip('horizontal'),\n",
    "  tf.keras.layers.RandomRotation(0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "img = cv2.imread('data/Test/Normal_Apple/normal_2.jpg')\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = tf.keras.preprocessing.image.load_img(image_path)\n",
    "input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
    "input_arr = np.array([input_arr])  # Convert single image to a batch.\n",
    "predictions = model.predict(input_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv2.imread('data/Test/Normal_Apple/normal_2.jpg')  # this is a PIL image\n",
    "# img = load_img('data/Train/Normal_Apple/normal_1.jpg')\n",
    "img = tf.keras.preprocessing.image.load_img('data/Train/Normal_Apple/normal_1.jpg')\n",
    "input_arr = tf.keras.preprocessing.image.img_to_array(img)\n",
    "input_arr = np.array([input_arr])\n",
    "\n",
    "# # the .flow() command below generates batches of randomly transformed images\n",
    "# # and saves the results to the `preview/` directory\n",
    "i = 0\n",
    "for batch in datagen.flow(input_arr, batch_size=1,\n",
    "                          save_to_dir='data/Preview', save_prefix='normal', save_format='jpg'):\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VISUALISE TRAIN AND TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for idx, img in enumerate(train_batch[0][:4]):\n",
    "    ax[idx].imshow(img.astype(int))\n",
    "    ax[idx].title.set_text(train_batch[1][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for idx, img in enumerate(test_batch[0][:4]):\n",
    "    ax[idx].imshow(img.astype(int))\n",
    "    ax[idx].title.set_text(test_batch[1][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, _ in train_data.take(1):\n",
    "  plt.figure(figsize=(10, 10))\n",
    "  first_image = image[0]\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n",
    "    plt.imshow(augmented_image[0] / 255)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.map(lambda x,y: (x/255, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.map(lambda x,y: (x/255, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageCountTrain = len(train_data)\n",
    "print (imageCountTrain)\n",
    "imageCountTest = len(test_data)\n",
    "print (imageCountTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(train_data)*.8)\n",
    "val_size = int(len(train_data)*.2)\n",
    "test_size = int(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (train_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_data.take(train_size)\n",
    "val = train_data.skip(train_size).take(val_size)\n",
    "test = test_data.take(test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Build Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple sequential model\n",
    "num_classes = 4\n",
    "# lossFunction = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "# gdAlgorithm = keras.optimizers.Adam(learning_rate=0.001)\n",
    "# nrOfEpochs = 5\n",
    "img_height = 256\n",
    "img_width = 256\n",
    "image_size=(img_height, img_width)\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "def create_model():\n",
    "  model = tf.keras.Sequential([\n",
    "    keras.layers.Conv2D(32, 3,input_shape=(img_height, img_width, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(),\n",
    "    keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    keras.layers.MaxPooling2D(),\n",
    "    keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    keras.layers.MaxPooling2D(),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(num_classes)\n",
    "  ])\n",
    "\n",
    "  model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "  return model\n",
    "\n",
    "# Create a basic model instance\n",
    "model = create_model()\n",
    "\n",
    "# Display the model's architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir='logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tf.random.set_seed(221)\n",
    "hist = model.fit(train, epochs=10, validation_data=val, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Plot Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['loss'], color='teal', label='loss')\n",
    "plt.plot(hist.history['val_loss'], color='orange', label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hist.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['sparse_categorical_accuracy'], color='teal', label='sparse_categorical_accuracy')\n",
    "plt.plot(hist.history['val_sparse_categorical_accuracy'], color='orange', label='val_sparse_categorical_accuracy')\n",
    "fig.suptitle('sparse_categorical_accuracy', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = Precision()\n",
    "re = Recall()\n",
    "acc = BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in test_data.as_numpy_iterator(): \n",
    "    X, y = element\n",
    "    yhat = model.predict(X)\n",
    "    pred = (np.argmax(yhat, axis=-1))\n",
    "    # pre.update_state(y, yhat)\n",
    "    # re.update_state(y, yhat)\n",
    "    # acc.update_state(y, yhat)\n",
    "\n",
    "    # print (yhat)\n",
    "    # print (y)\n",
    "\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.plot(history.history['accuracy'], label='Train accuracy')\n",
    "# plt.plot(history_test.history['accuracy'], label = 'Test accuracy')\n",
    "\n",
    "actual = y\n",
    "predicted = pred\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(actual, predicted)\n",
    "\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = ['Blotch', 'Normal', 'Rot', 'Scab'])\n",
    "\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testscore = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pre.result(), re.result(), acc.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('data/Test/Normal_Apple/normal_2.jpg')\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = tf.image.resize(img, (256,256))\n",
    "plt.imshow(resize.numpy().astype(int))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(np.expand_dims(resize/255, 0))\n",
    "pred = np.argmax(yhat, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pred == [3]: print ('the model predicts an apple with scab')\n",
    "elif pred == [2]: print ('the model predicts an apple with rot')\n",
    "elif pred == [1]: print ('the model predicts this is a normal healthy apple')\n",
    "elif pred == [0]: print ('the model predicts this is a blotched apple')\n",
    "else: print ('the model also has no idea what you put in')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if num > 0:\n",
    "    print(\"Positive number\")\n",
    "elif num == 0:\n",
    "    print(\"Zero\")\n",
    "else:\n",
    "    print(\"Negative number\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Save the Model and test loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join('models','appleclassifier422.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = load_model('models/appleclassifier422.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_new = new_model.predict(np.expand_dims(resize/255, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_new = np.argmax(yhat_new, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pred_new == [3]: print ('the model predicts an apple with scab')\n",
    "elif pred_new == [2]: print ('the model predicts an apple with rot')\n",
    "elif pred_new == [1]: print ('the model predicts this is a normal healthy apple')\n",
    "elif pred_new == [0]: print ('the model predicts this is a blotched apple')\n",
    "else: print ('the model also has no idea what you put in')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De vragen die ik bij 2_1 nog had zijn beantwoord door uitwerking \n",
    "\n",
    "Nieuwe vraag:\n",
    "\n",
    "voor het aanmaken van de data moet ik soms onderstaand commando runnen bij foutmelding:\n",
    "\n",
    "find . -name \"*.DS_Store\" -type f -delete\n",
    "\n",
    "wat is dit?\n",
    "\n",
    "\n",
    "Van to do 1_2 zijn confusion matrix en plots afgehandeld\n",
    "\n",
    "new to do - \n",
    "To do - image rescalen naar 100x100\n",
    "expirimenteren met model / dataset en augmentation\n",
    "transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class albumentations.augmentations.transforms.ToGray\n",
    "\n",
    "\n",
    "class albumentations.augmentations.crops.transforms.RandomSizedBBoxSafeCrop (height, width, erosion_rate=0.0, interpolation=1, always_apply=False, p=1.0)\n",
    "\n",
    "albumentations.augmentations.geometric.transforms.Flip.apply (self, img, d=0, **params) \n",
    "\n",
    "d (int): code that specifies how to flip the input. 0 for vertical flipping, 1 for horizontal flipping, -1 for both vertical and horizontal flipping (which is also could be seen as rotating the input by 180 degrees).\n",
    "\n",
    "class albumentations.augmentations.geometric.transforms.HorizontalFlip\n",
    "\n",
    "\n",
    "class albumentations.augmentations.geometric.transforms.ShiftScaleRotate (shift_limit=0.0625, scale_limit=0.1, rotate_limit=45, interpolation=1, border_mode=4, value=None, mask_value=None, shift_limit_x=None, shift_limit_y=None, rotate_method='largest_box', always_apply=False, p=0.5) [view source on GitHub] Â¶\n",
    "Randomly apply affine transforms: translate, scale and rotate the input.\n",
    "\n",
    "\n",
    "class albumentations.augmentations.geometric.transforms.VerticalFlip\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ed663571a6b95854416caae2548ff2b282c207efa98e62a2556d9c76a2b9028c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
