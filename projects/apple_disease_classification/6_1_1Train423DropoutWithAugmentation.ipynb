{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying a Different Augmentation Strategy Per Class\n",
    "\n",
    "Let's say we wished to augment the MNIST dataset, but you wished to use a generator to supply a neural network with data. \n",
    "\n",
    "Ordinarily you could write a pipeline that would augment all the data, regardless of the class. However with MNIST you might want to have different pipelines for each of the 10 different classes. \n",
    "\n",
    "For example, it would make sense to flip images for the figure 8 both horizontally and vertically and still end up with feasible data. The figure 3 could be flipped vertically but not horizontally. Conversely, the figure 4 should not be flipped either horizontally or vertically. \n",
    "\n",
    "We can do this by creating 10 different pipelines, and adding or removing the appropriate operations from each pipeline as required.\n",
    "\n",
    "Augmentor does not support this natively, but it can be performed easily enough, and here we will learn how. \n",
    "\n",
    "First we import the required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import Augmentor\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import collections\n",
    "from PIL import Image\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below is necessary for starting Numpy generated random numbers\n",
    "# in a well-defined initial state.\n",
    "np.random.seed(123)\n",
    "\n",
    "# The below is necessary for starting core Python generated random numbers\n",
    "# in a well-defined state.\n",
    "random.seed(123)\n",
    "\n",
    "# The below set_seed() will make random number generation\n",
    "# in the TensorFlow backend have a well-defined initial state.\n",
    "# For further details, see:\n",
    "# https://www.tensorflow.org/api_docs/python/tf/random/set_seed\n",
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Point to a Root Directory\n",
    "\n",
    "Your root directory must contain subdirectories, one for each class in your machine learning classification problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root_directory = 'data/Train/*'\n",
    "\n",
    "# root_directory = \"/home/marcus/Documents/mnist/train/*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Scan for folders in the root directory\n",
    "\n",
    "We use `glob.glob()` to scan for all files in the `root_directory` and only choose those that are directories. These will be out classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folders (classes) found: ['Scab_Apple', 'Normal_Apple', 'Blotch_Apple', 'Rot_Apple'] \n"
     ]
    }
   ],
   "source": [
    "folders = []\n",
    "for f in glob.glob(root_directory):\n",
    "    if os.path.isdir(f):\n",
    "        folders.append(os.path.abspath(f))\n",
    "\n",
    "print(\"Folders (classes) found: %s \" % [os.path.split(x)[1] for x in folders])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create a pipeline for each class\n",
    "\n",
    "Now we create a pipeline object for each of the classes. MNIST consists of 10 digits, and each digit represents one class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder /Users/macbookpro/MakeAiWork2/projects/apple_disease_classification/data/Train/Scab_Apple:\n",
      "Initialised with 85 image(s) found.\n",
      "Output directory set to /Users/macbookpro/MakeAiWork2/projects/apple_disease_classification/data/Train/Scab_Apple/output.\n",
      "----------------------------\n",
      "\n",
      "Folder /Users/macbookpro/MakeAiWork2/projects/apple_disease_classification/data/Train/Normal_Apple:\n",
      "Initialised with 67 image(s) found.\n",
      "Output directory set to /Users/macbookpro/MakeAiWork2/projects/apple_disease_classification/data/Train/Normal_Apple/output.\n",
      "----------------------------\n",
      "\n",
      "Folder /Users/macbookpro/MakeAiWork2/projects/apple_disease_classification/data/Train/Blotch_Apple:\n",
      "Initialised with 116 image(s) found.\n",
      "Output directory set to /Users/macbookpro/MakeAiWork2/projects/apple_disease_classification/data/Train/Blotch_Apple/output.\n",
      "----------------------------\n",
      "\n",
      "Folder /Users/macbookpro/MakeAiWork2/projects/apple_disease_classification/data/Train/Rot_Apple:\n",
      "Initialised with 114 image(s) found.\n",
      "Output directory set to /Users/macbookpro/MakeAiWork2/projects/apple_disease_classification/data/Train/Rot_Apple/output.\n",
      "----------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipelines = {}\n",
    "for folder in folders:\n",
    "    print(\"Folder %s:\" % (folder))\n",
    "    pipelines[os.path.split(folder)[1]] = (Augmentor.Pipeline(folder))\n",
    "    print(\"\\n----------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can summarise what was scanned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Scab_Apple has 85 samples.\n",
      "Class Normal_Apple has 67 samples.\n",
      "Class Blotch_Apple has 116 samples.\n",
      "Class Rot_Apple has 114 samples.\n"
     ]
    }
   ],
   "source": [
    "for p in pipelines.values():\n",
    "    print(\"Class %s has %s samples.\" % (p.augmentor_images[0].class_label, len(p.augmentor_images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Add operations to the pipelines\n",
    "\n",
    "Here we will add operations to each of the pipelines. Some operations will be applied to all pipelines, others only to some pipelines.\n",
    "\n",
    "Here we add a rotate operation to all pipelines (and hence will be applied to all digits):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=90x90 at 0x7F8028BADAF0>: 100%|██████████| 1000/1000 [00:03<00:00, 280.21 Samples/s] \n",
      "Processing <PIL.Image.Image image mode=RGB size=90x90 at 0x7F806DBB9B20>: 100%|██████████| 1000/1000 [00:02<00:00, 358.73 Samples/s]  \n",
      "Processing <PIL.Image.Image image mode=RGB size=100x100 at 0x7F8028B93490>: 100%|██████████| 1000/1000 [00:04<00:00, 248.45 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=90x90 at 0x7F80598F97C0>: 100%|██████████| 1000/1000 [00:02<00:00, 355.17 Samples/s]  \n"
     ]
    }
   ],
   "source": [
    "# for pipeline in pipelines.values():\n",
    "#     pipeline.set_save_format(save_format=\"png\")\n",
    "#     pipeline.resize(probability=1, height=100, width=100) #resize all for speed\n",
    "#     pipeline.flip_left_right(probability=0.3) #article flip\n",
    "#     pipeline.rotate(probability=0.3, max_left_rotation=0.2, max_right_rotation=0.2) # in addition to flip\n",
    "#     pipeline.zoom(probability=0.7, min_factor=1.1, max_factor=1.2) #article scale\n",
    "#     pipeline.crop_centre(probability=0.3, percentage_area=0.9) #article crop\n",
    "#     pipeline.random_color(probability=0.5, min_factor=0.4, max_factor=0.9) #artice color\n",
    "#     pipeline.random_contrast(probability=0.5, min_factor=0.9, max_factor=1.4) #article color\n",
    "#     pipeline.sample(1000)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we add some operations that we only want to apply to certain classes. The figure 8 can be flipped horizontally and vertically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pipelines[\"Normal_Apple\"].flip_left_right(probability=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define a class label / class integer map\n",
    "\n",
    "The classes will have string labels associated with them, depending on the name of each class's parent folder. Here you must map the names of each of your classes with the 0-based index (which must correspond to the test data of your dataset).\n",
    "\n",
    "In the case of MNIST this is quite easy, the samples for the digit 0 were stored in a folder 0 and have the text label 0, and so on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "integer_labels = {'Blotch_Apple': 0, \n",
    "                  'Normal_Apple': 1, \n",
    "                  'Rot_Apple': 2, \n",
    "                  'Scab_Apple': 3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Define pipeline containers to store the pipelines and additional information\n",
    "\n",
    "Later we will need each pipeline's 0-based integer label as well as its categorical label (depending on the type of neural network you define):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PipelineContainer = collections.namedtuple('PipelineContainer', \n",
    "                                           'label label_integer label_categorical pipeline generator')\n",
    "\n",
    "pipeline_containers = []\n",
    "\n",
    "for label, pipeline in pipelines.items():\n",
    "    label_categorical = np.zeros(len(pipelines), dtype=int)\n",
    "    label_categorical[integer_labels[label]] = 1\n",
    "    pipeline_containers.append(PipelineContainer(label, \n",
    "                                                 integer_labels[label], \n",
    "                                                 label_categorical, \n",
    "                                                 pipeline, \n",
    "                                                 pipeline.keras_generator(batch_size=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Define a generator function\n",
    "\n",
    "Neural networks in Keras can be supplied with a generator to supply training data. Because we have one generator for each pipeline, we need to create \"generator of generators\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def multi_generator(pipeline_containers, batch_size):\n",
    "    while True:\n",
    "        X = []\n",
    "        y = []\n",
    "        for i in range(batch_size):\n",
    "            pipeline_container = random.choice(pipeline_containers)\n",
    "            image, _ = next(pipeline_container.generator)\n",
    "            image = image.reshape((100, 100, 3)) # Or (1, 28, 28) for channels_first, see Keras' docs.\n",
    "            X.append(image)\n",
    "            y.append(pipeline_container.label_categorical)  # Or label_integer if required by network\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y)\n",
    "        yield X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Create the generator object\n",
    "\n",
    "Create a generator, `g` to pass data randomly from each pipeline (and hence each class) to a neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "g = multi_generator(pipeline_containers=pipeline_containers, \n",
    "                    batch_size=batch_size)  # Here the batch size can be set to any value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/macbookpro/MakeAiWork2/projects/apple_disease_classification/6_1_1Train423DropoutWithAugmentation.ipynb Cell 24\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/macbookpro/MakeAiWork2/projects/apple_disease_classification/6_1_1Train423DropoutWithAugmentation.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m (np\u001b[39m.\u001b[39mshape(X)[\u001b[39m0\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "(np.shape(X)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "32 x 100 x 100 x 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate a batch of 32 images (np.shape 32,100,100,3) and labels (np.shape y =32), at random from a random pipeline defined above, we can use the `next()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 24300 into shape (100,100,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/macbookpro/MakeAiWork2/projects/apple_disease_classification/6_1_1Train423DropoutWithAugmentation.ipynb Cell 27\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/macbookpro/MakeAiWork2/projects/apple_disease_classification/6_1_1Train423DropoutWithAugmentation.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(g)\n",
      "\u001b[1;32m/Users/macbookpro/MakeAiWork2/projects/apple_disease_classification/6_1_1Train423DropoutWithAugmentation.ipynb Cell 27\u001b[0m in \u001b[0;36mmulti_generator\u001b[0;34m(pipeline_containers, batch_size)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/macbookpro/MakeAiWork2/projects/apple_disease_classification/6_1_1Train423DropoutWithAugmentation.ipynb#X34sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m pipeline_container \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39mchoice(pipeline_containers)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/macbookpro/MakeAiWork2/projects/apple_disease_classification/6_1_1Train423DropoutWithAugmentation.ipynb#X34sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m image, _ \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(pipeline_container\u001b[39m.\u001b[39mgenerator)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/macbookpro/MakeAiWork2/projects/apple_disease_classification/6_1_1Train423DropoutWithAugmentation.ipynb#X34sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m image \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39;49mreshape((\u001b[39m100\u001b[39;49m, \u001b[39m100\u001b[39;49m, \u001b[39m3\u001b[39;49m)) \u001b[39m# Or (1, 28, 28) for channels_first, see Keras' docs.\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/macbookpro/MakeAiWork2/projects/apple_disease_classification/6_1_1Train423DropoutWithAugmentation.ipynb#X34sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m X\u001b[39m.\u001b[39mappend(image)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/macbookpro/MakeAiWork2/projects/apple_disease_classification/6_1_1Train423DropoutWithAugmentation.ipynb#X34sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m y\u001b[39m.\u001b[39mappend(pipeline_container\u001b[39m.\u001b[39mlabel_categorical)  \u001b[39m# Or label_integer if required by network\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 24300 into shape (100,100,3)"
     ]
    }
   ],
   "source": [
    "X, y = next(g)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can confirm that we are receiving images in batches of 128 and that the labels correspond to the images in each pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (np.shape(X))\n",
    "print (len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (type(X[4]))\n",
    "\n",
    "print (y[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use PIL to view the augmented images and cofirm the labels match (note that PIL requires images to be specified differently to how Keras expects data, hence some preprocessing of the data must be performed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_index = 8  # Take image index 3 from the batch\n",
    "\n",
    "x_array = X[image_index]\n",
    "# x_array = x_array.reshape((100,100))\n",
    "x_array = x_array * 255\n",
    "x_array = x_array.astype(np.uint8)\n",
    "Image.fromarray(x_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The label below should correspond to the image output above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Image label: %s\" % (np.nonzero(y[image_index])[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Train a neural network with the generator\n",
    "\n",
    "Last, we train a neural network with the differing pipelines for each class.\n",
    "\n",
    "First we define a neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_classes = 4\n",
    "# lossFunction = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "# gdAlgorithm = keras.optimizers.Adam(learning_rate=0.001)\n",
    "# nrOfEpochs = 5\n",
    "img_height = 100\n",
    "img_width = 100\n",
    "image_size=(img_height, img_width)\n",
    "batch_size = 32\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  keras.layers.Conv2D(32, 3,input_shape=(img_height, img_width, 3), activation='relu'),\n",
    "  keras.layers.MaxPooling2D(),\n",
    "  keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  keras.layers.MaxPooling2D(),\n",
    "  keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  keras.layers.MaxPooling2D(),\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(128, activation='relu'),\n",
    "  keras.layers.Dropout(0.3),\n",
    "  keras.layers.Dense ((num_classes),activation='softmax')\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once a network has been defined, you can compile it so that the model is ready to be trained with data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adadelta',\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "            metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "# Display the model's architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "#               optimizer=keras.optimizers.Adadelta(),\n",
    "#               metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same batch size as the generator above, we can begin to train the neural network: 1st try = 382 sample / 32 batch size = 12/epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h = model.fit_generator(g, steps_per_epoch=382/batch_size, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['loss'], color='teal', label='loss')\n",
    "plt.plot(hist.history['val_loss'], color='orange', label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hist.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['sparse_categorical_accuracy'], color='teal', label='sparse_categorical_accuracy')\n",
    "plt.plot(hist.history['val_sparse_categorical_accuracy'], color='orange', label='val_sparse_categorical_accuracy')\n",
    "fig.suptitle('sparse_categorical_accuracy', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in test_data.as_numpy_iterator(): \n",
    "    X, y = element\n",
    "    yhat = model.predict(X)\n",
    "    pred = (np.argmax(yhat, axis=-1))\n",
    "    # pre.update_state(y, yhat)\n",
    "    # re.update_state(y, yhat)\n",
    "    # acc.update_state(y, yhat)\n",
    "\n",
    "    # print (yhat)\n",
    "    # print (y)\n",
    "\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.plot(history.history['accuracy'], label='Train accuracy')\n",
    "# plt.plot(history_test.history['accuracy'], label = 'Test accuracy')\n",
    "\n",
    "actual = y\n",
    "predicted = pred\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(actual, predicted)\n",
    "\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = ['Blotch', 'Normal', 'Rot', 'Scab'])\n",
    "\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testscore = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pre.result(), re.result(), acc.result())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ed663571a6b95854416caae2548ff2b282c207efa98e62a2556d9c76a2b9028c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
