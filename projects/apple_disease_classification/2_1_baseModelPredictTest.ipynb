{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hoQQiZDB6URn"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T01:23:15.333279Z",
     "iopub.status.busy": "2022-07-12T01:23:15.332913Z",
     "iopub.status.idle": "2022-07-12T01:23:17.505753Z",
     "shell.execute_reply": "2022-07-12T01:23:17.505026Z"
    },
    "id": "3vhAMaIOBIee"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T01:23:17.510026Z",
     "iopub.status.busy": "2022-07-12T01:23:17.509351Z",
     "iopub.status.idle": "2022-07-12T01:23:17.513194Z",
     "shell.execute_reply": "2022-07-12T01:23:17.512616Z"
    },
    "id": "Qnp9Z2sT5dWj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wwZavzgsIytz"
   },
   "source": [
    "To train a model with this dataset you will want the data:\n",
    "\n",
    "* To be well shuffled.\n",
    "* To be batched.\n",
    "* Batches to be available as soon as possible.\n",
    "\n",
    "These features can be added using the `tf.data` API. For more details, visit the [Input Pipeline Performance](../../guide/performance/datasets.ipynb) guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUTOTUNE IS EEN EXPIRIMENT VOOR LATER, ZORGT ER NU VOOR DAT MODEL NIET GOED LAADT VOOR TRAINING\n",
    "\n",
    "# AUTOTUNE = tf.data.AUTOTUNE \n",
    "\n",
    "# # train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "# # val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# def configure_for_performance(ds):\n",
    "#   ds = ds.cache()\n",
    "#   ds = ds.shuffle(buffer_size=1000)\n",
    "#   ds = ds.batch(batch_size)\n",
    "#   ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "#   return ds\n",
    "\n",
    "# train_ds = configure_for_performance(train_ds)\n",
    "# val_ds = configure_for_performance(val_ds)\n",
    "# test_ds = configure_for_performance(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_classes = 5 geen idee waarom model.summary niet werkt\n",
    "\n",
    "# def create_model():\n",
    "#   model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Rescaling(1./255),\n",
    "#     tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "#     tf.keras.layers.MaxPooling2D(),\n",
    "#     tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "#     tf.keras.layers.MaxPooling2D(),\n",
    "#     tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "#     tf.keras.layers.MaxPooling2D(),\n",
    "#     tf.keras.layers.Flatten(),\n",
    "#     tf.keras.layers.Dense(128, activation='relu'),\n",
    "#     tf.keras.layers.Dense(num_classes)\n",
    "# ])\n",
    "\n",
    "#   model.compile(optimizer='adam',\n",
    "#     loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#     metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "#   return model\n",
    "\n",
    "# Create a basic model instance\n",
    "# model = create_model()\n",
    "\n",
    "# # Display the model's architecture\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Rescaling(1./255, input_shape(img_height, img_width, 3)),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d83f5aa7f3fb"
   },
   "source": [
    "Choose the `tf.keras.optimizers.Adam` optimizer and `tf.keras.losses.SparseCategoricalCrossentropy` loss function. To view training and validation accuracy for each training epoch, pass the `metrics` argument to `Model.compile`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ffwd44ldNMOE"
   },
   "source": [
    "Note: You will only train for a few epochs so this tutorial runs quickly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T01:23:26.847829Z",
     "iopub.status.busy": "2022-07-12T01:23:26.847370Z",
     "iopub.status.idle": "2022-07-12T01:23:37.497066Z",
     "shell.execute_reply": "2022-07-12T01:23:37.496387Z"
    },
    "id": "S08ZKKODsnGW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "306/306 [==============================] - ETA: 0s - loss: 1.2686 - sparse_categorical_accuracy: 0.4706\n",
      "Epoch 1: saving model to training_1/cp.ckpt\n",
      "306/306 [==============================] - 27s 89ms/step - loss: 1.2686 - sparse_categorical_accuracy: 0.4706 - val_loss: 1.0808 - val_sparse_categorical_accuracy: 0.5921\n",
      "Epoch 2/10\n",
      "306/306 [==============================] - ETA: 0s - loss: 1.0463 - sparse_categorical_accuracy: 0.6275\n",
      "Epoch 2: saving model to training_1/cp.ckpt\n",
      "306/306 [==============================] - 27s 89ms/step - loss: 1.0463 - sparse_categorical_accuracy: 0.6275 - val_loss: 0.8460 - val_sparse_categorical_accuracy: 0.6842\n",
      "Epoch 3/10\n",
      "306/306 [==============================] - ETA: 0s - loss: 0.7184 - sparse_categorical_accuracy: 0.7320\n",
      "Epoch 3: saving model to training_1/cp.ckpt\n",
      "306/306 [==============================] - 28s 90ms/step - loss: 0.7184 - sparse_categorical_accuracy: 0.7320 - val_loss: 0.8909 - val_sparse_categorical_accuracy: 0.7237\n",
      "Epoch 4/10\n",
      "306/306 [==============================] - ETA: 0s - loss: 0.8442 - sparse_categorical_accuracy: 0.7647\n",
      "Epoch 4: saving model to training_1/cp.ckpt\n",
      "306/306 [==============================] - 29s 95ms/step - loss: 0.8442 - sparse_categorical_accuracy: 0.7647 - val_loss: 1.0453 - val_sparse_categorical_accuracy: 0.6842\n",
      "Epoch 5/10\n",
      "306/306 [==============================] - ETA: 0s - loss: 0.5571 - sparse_categorical_accuracy: 0.8170\n",
      "Epoch 5: saving model to training_1/cp.ckpt\n",
      "306/306 [==============================] - 29s 94ms/step - loss: 0.5571 - sparse_categorical_accuracy: 0.8170 - val_loss: 1.1208 - val_sparse_categorical_accuracy: 0.6711\n",
      "Epoch 6/10\n",
      "306/306 [==============================] - ETA: 0s - loss: 0.5497 - sparse_categorical_accuracy: 0.8431\n",
      "Epoch 6: saving model to training_1/cp.ckpt\n",
      "306/306 [==============================] - 30s 97ms/step - loss: 0.5497 - sparse_categorical_accuracy: 0.8431 - val_loss: 1.4390 - val_sparse_categorical_accuracy: 0.6447\n",
      "Epoch 7/10\n",
      "306/306 [==============================] - ETA: 0s - loss: 0.3090 - sparse_categorical_accuracy: 0.9183\n",
      "Epoch 7: saving model to training_1/cp.ckpt\n",
      "306/306 [==============================] - 29s 95ms/step - loss: 0.3090 - sparse_categorical_accuracy: 0.9183 - val_loss: 1.1636 - val_sparse_categorical_accuracy: 0.6842\n",
      "Epoch 8/10\n",
      "306/306 [==============================] - ETA: 0s - loss: 0.2611 - sparse_categorical_accuracy: 0.9412\n",
      "Epoch 8: saving model to training_1/cp.ckpt\n",
      "306/306 [==============================] - 30s 98ms/step - loss: 0.2611 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.7928 - val_sparse_categorical_accuracy: 0.7368\n",
      "Epoch 9/10\n",
      "306/306 [==============================] - ETA: 0s - loss: 0.1440 - sparse_categorical_accuracy: 0.9477\n",
      "Epoch 9: saving model to training_1/cp.ckpt\n",
      "306/306 [==============================] - 32s 103ms/step - loss: 0.1440 - sparse_categorical_accuracy: 0.9477 - val_loss: 1.8164 - val_sparse_categorical_accuracy: 0.7105\n",
      "Epoch 10/10\n",
      "306/306 [==============================] - ETA: 0s - loss: 0.1396 - sparse_categorical_accuracy: 0.9739\n",
      "Epoch 10: saving model to training_1/cp.ckpt\n",
      "306/306 [==============================] - 32s 103ms/step - loss: 0.1396 - sparse_categorical_accuracy: 0.9739 - val_loss: 1.9099 - val_sparse_categorical_accuracy: 0.7105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe3b26936d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checkpoint_path = \"training_1/cp.ckpt\"\n",
    "# checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# # Create a callback that saves the model's weights\n",
    "# cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "#                                                  save_weights_only=True,\n",
    "#                                                  verbose=1)\n",
    "#                                                  # save_freq=5*batch_size) terug aan als batch omhoog gaat\n",
    "\n",
    "model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=10)\n",
    "#   callbacks=[cp_callback])  # Pass callback to training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.listdir(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Dataset had more than one element. [Op:DatasetToSingleElement]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/Users/macbookpro/MakeAiWork2/projects/apple_disease_classification/baseModelPredictTest.ipynb Cell 43\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/macbookpro/MakeAiWork2/projects/apple_disease_classification/baseModelPredictTest.ipynb#Y101sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m (test_ds\u001b[39m.\u001b[39;49mget_single_element(\u001b[39m0\u001b[39;49m))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:2636\u001b[0m, in \u001b[0;36mDatasetV2.get_single_element\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2632\u001b[0m \u001b[39mif\u001b[39;00m name:\n\u001b[1;32m   2633\u001b[0m   metadata\u001b[39m.\u001b[39mname \u001b[39m=\u001b[39m _validate_and_encode(name)\n\u001b[1;32m   2634\u001b[0m \u001b[39mreturn\u001b[39;00m structure\u001b[39m.\u001b[39mfrom_compatible_tensor_list(\n\u001b[1;32m   2635\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39melement_spec,\n\u001b[0;32m-> 2636\u001b[0m     gen_dataset_ops\u001b[39m.\u001b[39;49mdataset_to_single_element(\n\u001b[1;32m   2637\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variant_tensor,\n\u001b[1;32m   2638\u001b[0m         metadata\u001b[39m=\u001b[39;49mmetadata\u001b[39m.\u001b[39;49mSerializeToString(),\n\u001b[1;32m   2639\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_structure))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/gen_dataset_ops.py:1318\u001b[0m, in \u001b[0;36mdataset_to_single_element\u001b[0;34m(dataset, output_types, output_shapes, metadata, name)\u001b[0m\n\u001b[1;32m   1316\u001b[0m   \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m   1317\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 1318\u001b[0m   _ops\u001b[39m.\u001b[39;49mraise_from_not_ok_status(e, name)\n\u001b[1;32m   1319\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_FallbackException:\n\u001b[1;32m   1320\u001b[0m   \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:7186\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7184\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7185\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 7186\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dataset had more than one element. [Op:DatasetToSingleElement]"
     ]
    }
   ],
   "source": [
    "# print (test_ds.get_single_elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "    return file_path.split(\"\\\\\")[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 2 3 2 1 2 2 1 0 2 0 3 2 0 1 3 2 2 2 2 3 0 2 0 2 3 2 0 0 3 0 0 0 0 0 1\n",
      " 0 0 0 2 3 3 0 3 0 2 3 2 1 1 0 3 1 0 2 0 0 2 0 2 3 3 2 3 3 0 0 2 0 0 2 2 2\n",
      " 2 0 2 0 1 0 2 3 3 2 0 1 1 2 3 2 2 2 3 3 0 0 2 0 0 1 0 1 3 3 0 1 0 3 0 0 2\n",
      " 2 2 0 2 2 0 3 2 3]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n\n    TypeError: tf__get_label() takes 1 positional argument but 2 were given\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/macbookpro/MakeAiWork2/projects/apple_disease_classification/baseModelPredictTest.ipynb Cell 54\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/macbookpro/MakeAiWork2/projects/apple_disease_classification/baseModelPredictTest.ipynb#X60sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(pred)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/macbookpro/MakeAiWork2/projects/apple_disease_classification/baseModelPredictTest.ipynb#X60sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# original labels\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/macbookpro/MakeAiWork2/projects/apple_disease_classification/baseModelPredictTest.ipynb#X60sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m actual \u001b[39m=\u001b[39m test_ds\u001b[39m.\u001b[39;49mmap(get_label)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/macbookpro/MakeAiWork2/projects/apple_disease_classification/baseModelPredictTest.ipynb#X60sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(actual)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:2016\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2013\u001b[0m   \u001b[39mif\u001b[39;00m deterministic \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m DEBUG_MODE:\n\u001b[1;32m   2014\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2015\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39m`num_parallel_calls` argument is specified.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 2016\u001b[0m   \u001b[39mreturn\u001b[39;00m MapDataset(\u001b[39mself\u001b[39;49m, map_func, preserve_cardinality\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m   2017\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2018\u001b[0m   \u001b[39mreturn\u001b[39;00m ParallelMapDataset(\n\u001b[1;32m   2019\u001b[0m       \u001b[39mself\u001b[39m,\n\u001b[1;32m   2020\u001b[0m       map_func,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2023\u001b[0m       preserve_cardinality\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   2024\u001b[0m       name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:5191\u001b[0m, in \u001b[0;36mMapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m   5189\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_inter_op_parallelism \u001b[39m=\u001b[39m use_inter_op_parallelism\n\u001b[1;32m   5190\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preserve_cardinality \u001b[39m=\u001b[39m preserve_cardinality\n\u001b[0;32m-> 5191\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func \u001b[39m=\u001b[39m structured_function\u001b[39m.\u001b[39;49mStructuredFunctionWrapper(\n\u001b[1;32m   5192\u001b[0m     map_func,\n\u001b[1;32m   5193\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transformation_name(),\n\u001b[1;32m   5194\u001b[0m     dataset\u001b[39m=\u001b[39;49minput_dataset,\n\u001b[1;32m   5195\u001b[0m     use_legacy_function\u001b[39m=\u001b[39;49muse_legacy_function)\n\u001b[1;32m   5196\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata \u001b[39m=\u001b[39m dataset_metadata_pb2\u001b[39m.\u001b[39mMetadata()\n\u001b[1;32m   5197\u001b[0m \u001b[39mif\u001b[39;00m name:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:271\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m       warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    265\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    266\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    267\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    268\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    269\u001b[0m     fn_factory \u001b[39m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 271\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function \u001b[39m=\u001b[39m fn_factory()\n\u001b[1;32m    272\u001b[0m \u001b[39m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    273\u001b[0m add_to_graph \u001b[39m&\u001b[39m\u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3070\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3061\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_concrete_function\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   3062\u001b[0m   \u001b[39m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[1;32m   3063\u001b[0m \n\u001b[1;32m   3064\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[39m       or `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[1;32m   3069\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3070\u001b[0m   graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_concrete_function_garbage_collected(\n\u001b[1;32m   3071\u001b[0m       \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   3072\u001b[0m   graph_function\u001b[39m.\u001b[39m_garbage_collector\u001b[39m.\u001b[39mrelease()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   3073\u001b[0m   \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3036\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3034\u001b[0m   args, kwargs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   3035\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m-> 3036\u001b[0m   graph_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[1;32m   3037\u001b[0m   seen_names \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[1;32m   3038\u001b[0m   captured \u001b[39m=\u001b[39m object_identity\u001b[39m.\u001b[39mObjectIdentitySet(\n\u001b[1;32m   3039\u001b[0m       graph_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39minternal_captures)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3292\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3288\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[1;32m   3289\u001b[0m       args, kwargs, flat_args, filtered_flat_args)\n\u001b[1;32m   3291\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39madd_call_context(cache_key\u001b[39m.\u001b[39mcall_context)\n\u001b[0;32m-> 3292\u001b[0m graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_graph_function(args, kwargs)\n\u001b[1;32m   3293\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39madd(cache_key, cache_key_deletion_observer,\n\u001b[1;32m   3294\u001b[0m                          graph_function)\n\u001b[1;32m   3296\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3130\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3125\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[1;32m   3126\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   3127\u001b[0m ]\n\u001b[1;32m   3128\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[1;32m   3129\u001b[0m graph_function \u001b[39m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 3130\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[1;32m   3131\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[1;32m   3132\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[1;32m   3133\u001b[0m         args,\n\u001b[1;32m   3134\u001b[0m         kwargs,\n\u001b[1;32m   3135\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_signature,\n\u001b[1;32m   3136\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[1;32m   3137\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[1;32m   3138\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[1;32m   3139\u001b[0m         override_flat_arg_shapes\u001b[39m=\u001b[39;49moverride_flat_arg_shapes,\n\u001b[1;32m   3140\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[1;32m   3141\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[1;32m   3142\u001b[0m     function_spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[1;32m   3143\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   3144\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   3145\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   3146\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   3147\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   3148\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1161\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1158\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1159\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1161\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[1;32m   1163\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1164\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1165\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[1;32m   1166\u001b[0m                                   expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:248\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[39m@eager_function\u001b[39m\u001b[39m.\u001b[39mdefun_with_attributes(\n\u001b[1;32m    243\u001b[0m     input_signature\u001b[39m=\u001b[39mstructure\u001b[39m.\u001b[39mget_flat_tensor_specs(\n\u001b[1;32m    244\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_structure),\n\u001b[1;32m    245\u001b[0m     autograph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    246\u001b[0m     attributes\u001b[39m=\u001b[39mdefun_kwargs)\n\u001b[1;32m    247\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_fn\u001b[39m(\u001b[39m*\u001b[39margs):  \u001b[39m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[0;32m--> 248\u001b[0m   ret \u001b[39m=\u001b[39m wrapper_helper(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    249\u001b[0m   ret \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39mto_tensor_list(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_structure, ret)\n\u001b[1;32m    250\u001b[0m   \u001b[39mreturn\u001b[39;00m [ops\u001b[39m.\u001b[39mconvert_to_tensor(t) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m ret]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:177\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[1;32m    176\u001b[0m   nested_args \u001b[39m=\u001b[39m (nested_args,)\n\u001b[0;32m--> 177\u001b[0m ret \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39;49mtf_convert(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func, ag_ctx)(\u001b[39m*\u001b[39;49mnested_args)\n\u001b[1;32m    178\u001b[0m \u001b[39mif\u001b[39;00m _should_pack(ret):\n\u001b[1;32m    179\u001b[0m   ret \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(ret)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:692\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 692\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[1;32m    693\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    694\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n\n    TypeError: tf__get_label() takes 1 positional argument but 2 were given\n"
     ]
    }
   ],
   "source": [
    "#simplest predictions\n",
    "\n",
    "pred = model.predict(test_ds)\n",
    "\n",
    "pred = np.argmax(pred, axis=-1)\n",
    "\n",
    "print(pred)\n",
    "\n",
    "# original labels\n",
    "\n",
    "actual = np.argmax(test_ds.map(get_label))\n",
    "\n",
    "print(actual)\n",
    "\n",
    "\n",
    "# conf_matrix = tf.math.confusion_matrix(labels=class_names, predictions=pred)\n",
    "\n",
    "# print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #predict tf?\n",
    "\n",
    "# predict_ds = tf.data.Dataset.from_tensor_slices(images).batch(32)\n",
    "# result = model.predict(predict_ds, steps = 10)\n",
    "# print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'BatchDataset' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/macbookpro/MakeAiWork2/projects/apple_disease_classification/baseModelPredictTest.ipynb Cell 44\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/macbookpro/MakeAiWork2/projects/apple_disease_classification/baseModelPredictTest.ipynb#X65sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m i \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/macbookpro/MakeAiWork2/projects/apple_disease_classification/baseModelPredictTest.ipynb#X65sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m#dit is het plaatje van index i\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/macbookpro/MakeAiWork2/projects/apple_disease_classification/baseModelPredictTest.ipynb#X65sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m img \u001b[39m=\u001b[39m train_ds[i]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/macbookpro/MakeAiWork2/projects/apple_disease_classification/baseModelPredictTest.ipynb#X65sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m (img)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'BatchDataset' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# predictions met plot\n",
    "\n",
    "#hier kies je welke index je iets mee wilt\n",
    "i = 1\n",
    "\n",
    "#dit is het plaatje van index i\n",
    "img = train_ds[i]\n",
    "\n",
    "print (img)\n",
    "\n",
    "# img_array = tf.keras.utils.img_to_array(img)\n",
    "# img_array = tf.expand_dims(img_array, 0) # Change dims to fit model\n",
    "\n",
    "# predictions = model.predict(img_array)\n",
    "# score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "# print(\n",
    "#     \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "#     .format(labelNames[np.argmax(score)], 100 * np.max(score))\n",
    "# )\n",
    "\n",
    "# # # print de label naam van index i\n",
    "# print(labelNames[trainLabels[i]])\n",
    "\n",
    "# # #laat plaatje zien\n",
    "# plt.imshow(img)\n",
    "\n",
    "# print(img.shape)\n",
    "# # print(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vragen:\n",
    "\n",
    "labels zijn 0-1-2-3 ipv blotch, normal , rot en scab\n",
    "\n",
    "prediction is np array ipv %\n",
    "\n",
    "opslaan en ophalen met checkpoints?\n",
    "\n",
    "hoe grijp ik elementen aan uit een tf dataset?"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "images.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ed663571a6b95854416caae2548ff2b282c207efa98e62a2556d9c76a2b9028c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
